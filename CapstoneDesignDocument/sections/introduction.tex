\chapter{Introduction}


\section{Problem Statement}
%-------------------------------------------%

Artificial intelligence (hereafter referred to as AI) in video games has often been used for either academic research or customer analytics. We are a team of two undergraduate researchers who wish to see cutting-edge machine learning techniques, such as recurrent neural networks, applied in a way with which the general public can interact and, ultimately, have fun.

%-------------------------------------------%



\section{Purpose Statement}
%-------------------------------------------%

 In order to employ machine learning techniques as a means for entertainment, this project seeks to develop a videogame AI opponent that is fun to play against. The AI shall only be able to make use of the visual buffer as its input. There are two reasons for this constraint. Firstly and chiefly, the visual buffer is readily available from outside of the game's runtime, and can therefore be obtained without the use of hooks or APIs provided by said runtime. This decouples the techniques used to inform and train the agent from any specific game implementation, thereby rendering those techniques reusable. Secondly, if the AI can effectively play with only access to the visual buffer, then it will essentially be playing with the same information with which a human would play. Additionally, this constraint further differentiates the AI from conventional game agents, which are allowed to make decisions based on explicit and concisely packaged game state information such as coordinates, predefined navigational paths, and health points.
 
 The AI produced in this project will play Rivals of Aether, which is a two-dimensional or 2D fighting game created by independent game developer Dan Fornace \cite{RivalsofAether}.

%-------------------------------------------%



\section{Context}
%-------------------------------------------%

Interest in the field of artificial intelligence has been present since nearly the beginning of computing. However, over the past few years interest in AI has been growing considerably. With the recent popularity of machine learning techniques like neural networks, many researchers have made huge advancements in the field. Companies such as Google are frequently appearing in mainstream media for their groundbreaking projects. Google's AlphaGo is an amazing example of the work that can be done; AlphaGo is an AI was able to beat the world's best Go player, and it continues to improve its game \cite{AlphaGo}. Other groups are contributing to the advancement of AI, although they are not as easily recognizable. A research platform called ViZDoom is one such example that closely relates to our work. ViZDoom is an Open Source platform that allows users to create agents in the videogame Doom, these game agents are doing what any human player would: trying to maximize their score. However, unlike more conventional game AI, they are playing using only the visual buffer. This approach more closely resembles how humans play the game, and was also a large inspiration to this project. Yet, ViZDoom is still primarily a research platform \cite{Kempka:2016}.

Furthermore, game-related AI research is limited by the actual games that are viable for machine learning. Regardless of one's approach, one will require either labeled training data, access to the game's internal state, or both; the former can be time-consuming to generate and the latter may not even be achievable. As a result, there are two games in particular that tend to be the focus of AI research: Doom and Quake. What sets them apart from other games is that they support the recording demos, which are files that keep a record of what controller inputs were detected from which player during each moment of gameplay. Thus, whereas a conventional video recording associates each frame with its pixel data, a replay does so with each timestamp or frame and its input data. This allows the game to simulate a past match in real-time with perfect accuracy by simply running a new match in which each player's control input is read from the replay file rather than from the controller. An AI can use a collection of these demos to essentially reverse-engineer how to play the game by simultaneously watching the demo and studying the corresponding input data. Doom and Quake are made further popular for AI research because there are immense repositories of demo files available on the world wide web, from websites such as Speed Demo Archives and Quake Terminus \cite{Thurau:2004}.

Finding cutting-edge AI techniques in the game industry is quite hard. Many developers find these techniques to be both impractical and excessive. These implementations use up sought after resources. Why should they create more work for themselves when many of the problems that we are looking to solve can be reduced to smaller problems with nice well defined algorithms? With this information, one may think that almost no one uses advanced A.I. in games, and that is primarily the case. However, some companies are implementing these advanced techniques. Instead of using AI to create a more unique and enjoyable experience, however, they use it to push sales for specific features. This is the case with Activision's recently acquired patent, which defines a method for manipulating players into engaging with micro-transactions \cite{Marr:2017}.

%-------------------------------------------%


\section{Significance of Project}
%-------------------------------------------%

This project is, at least in part, a response to what we perceive to be a rising trend in the games industry for machine learning to be used for purposes which can be best summed up as customer manipulation and greed. At the time of writing, AI is one of the quickest growing STEM fields. We believe that it is important to do our part in establishing a precedent, showing developers, publishers, and consumers what advanced AI can, and ultimately, ought to be used for.

This project is significant within its the niche of game-related AI research because it introduces a hitherto unexplored game, Rivals of Aether, as a viable environment for supervised learning. Rivals of Aether supports the recording of replays, which are essentially the same kind of file as a demo. Unlike Quake and Doom, however, there are no well-established public repositories for replays. Therefore, in order to build our dataset, we solicited from the {\it Rivals of Aether} community. Contributors provided us with a total of 1,020 replay files from a variety of settings, including tournaments, exhibitions, ranked matches, and private games. Adding our own replays that we recorded ourselves brings the total up to 1,032.

%-------------------------------------------%
