\chapter{Literature (3-5 pages)}
\label{ch:Literature}



\section{Literature Overview}
%-------------------------------------------%

In {\it Towards Integrated Imitation of Strategic Planning and Motion Modeling in Interactive Computer Games}, Dublin City University researchers Bernard Gorman and Mark Humphrys detail their experiments in using imitation learning techniques to teach an artificial agent to play a first person shooter—in this case, Quake—in a way that would convince onlookers and other players that it is human. They describe a superior agent, which imitates "the observed goal-oriented behaviors of a human player," (p. 2) in order to play with competence, exhibit strategic thinking, and employ "believably human-like motion" (p. 1). In other words, they want to create a bot that can pass a kind of Turing deathmatch. Gorman and Humphrys describe the behavior model which serves as the basis for their work. The model specifies several levels of control, where each level corresponds with roughly how much time the agent has to form a plan. These range from immediate ("scrambled control") to long-term ("strategic control"). Furthermore, their model relates these levels of control to three kinds of behavior—strategic, tactical, and reactive—which together are supposed to form the building blocks for an agent's motion modeling capabilities (p. 3). In their experiments, Gorman and Humphrys emphasize the "human-like motion" mentioned above. They limit the scope and complexity of their problem by only concerning their agent with the tasks of environmental navigation and item acquisition. Their methods involve topology learning (p. 3), Markov decision processes or MPDs (p. 4), and motion modeling based on "action primitives." The action primitives, the recorded gameplay, and relevant state space information comprise their training data (p. 6-7). They applied their agent in two types of tests: "pickup sequence" tests, in which the agent must pick up a series of items, and "continuous gameplay" tests, which were of a more free-roam nature (p. 8-9). The researchers noted that the agent performed "showed impressive performance and adaptability" during the pickup sequence tests (p. 8). Otherwise, they noted one issue in the continuous gameplay tests: the agent would sometimes struggle to choose among competing utilities (p. 10-11) \cite{Gorman:2006:TII:1178418.1178432}.

In {\it Autoencoder-augmented Neuroevolution for Visual Doom Playing}, Cornell University researchers Samuel Alvernaz and Julian Togelius explore the use of an autoencoder alongside a neuroevolution technique called "Covariance Matrix Adaptation Evolution Strategy" or CMA-ES. An autoencoder is essentially a process that simplifies and reconstructs images. The researchers implement their autoencoder using Keras, a high-level machine-learning library. They then use it to train their neural network in health-gathering exercises \cite{Alvernaz:2017}.

%-------------------------------------------%



\section{Software}
%-------------------------------------------%

Predecessor or current software projects related to your capstone area. May be libraries that you are incorporating in your project, projects that are inspiring your design, a project you are building on, etc...

%-------------------------------------------%



\section{Other Sources}
%-------------------------------------------%

Non-academic sources such as white papers, manuals, blogs, etc.

%-------------------------------------------%