\chapter{Literature (3-5 pages)}
\label{ch:Literature}



\section{Literature Overview}
%-------------------------------------------%

In {\it Towards Integrated Imitation of Strategic Planning and Motion Modeling in Interactive Computer Games}, Dublin City University researchers Bernard Gorman and Mark Humphrys train use imitation learning techniques to train an artificial agent to collect items in {\it Quake II}. Specifically, their agent must traverse three-dimensional environments in order to seek said items out without knowing their locations in advance. Furthermore, the researchers set an additional requirement: the agent must "employ human-like motion," which is to say that it must traverse the map in such a way that its movements appear fluid and natural, as if a human were controlling it. The researchers refer to this "imitation of the player's movement" as {\it motion modeling}, and it represents the main purpose of their experiments. Gorman et al create their training dataset by retrieving state information from demos. Specifically, they use topology learning techniques to define a Markov Decision Process based on all of the player and pickup positions recorded in the demo file. They then employ value iteration using information about the player's status, such as current health and inventory, which is also read from the demo file. Value iteration eventually assigns a utility to each state in the MDP and, ultimately, allows the agent to make intelligent decisions about where to travel next. Gorman et al proceed to discuss their approach in solving the problem of motion modeling. They define a set of {\it action primitives} by reading all of the input data from the demo file and then disassociating that data from its context. This allows the agent to, after deciding where to navigate, lay out a series of action primitives that will allow it to reach its goal \cite{Gorman:2006}.

Gorman et al cite {\it Learning human-like Movement Behavior for Computer Games} by Christian Thurau and Christian Bauckhage of Bielefeld University, an experimental study which provides a useful behavioral model while also challenging the conventional approach of creating agents based on simple finite state machines. Thurau et al define a hierarchy of behavior types consisting of reactive, tactical, and strategic behaviors \cite{Thurau:2004}. Strategic behaviors are essentially long-term plans for winning the game, such as which objectives to target and in what order. Contrast this with reactive behaviors, which are atomic, immediate decisions, such as moving in a particular direction, aiming, or firing a weapon. Tactical behaviors sit in between reactive and strategic, representing small-scale decisions such as circle-strafing an opponent or choosing to run away from a battle in order to look for a health pack \cite{Gorman:2006}. To implement an agent that utilizes such behaviors, Thurau et al employ topology learning techniques to train a type of neural network called a {\it neural gas}, using player position data extracted from demo files. The neural gas produces what are referred to as {\it position prototypes}, which are assigned to . This methodology should sound familiar; Gorman et al use many of the contributions detailed in the paper \cite{Thurau:2004}.

In {\it Autoencoder-augmented Neuroevolution for Visual Doom Playing}, Cornell University researchers Samuel Alvernaz and Julian Togelius explore the use of an autoencoder alongside a neuroevolution technique called "Covariance Matrix Adaptation Evolution Strategy" or CMA-ES. An autoencoder is essentially a process that simplifies and reconstructs images. The researchers implement their autoencoder using Keras, a high-level machine-learning library. They then the autoencoder's output as the input for their neural network, which they train to gather health pickups \cite{Alvernaz:2017}.

In {\it Learning to Act by Predicting the Future}, Cornell University researchers Alexey Dosovitskiy and Vladlen Koltun use supervised learning techniques to train an agent to play competitive deathmatches in {\it Doom}. Dosovitskiy and Koltun do so by using two distinctive data streams: one is high-dimensional and consists of "raw visual, auditory, and tactile input," while the other is low-dimensional and provides basic game state information such as "health, ammunition levels, and the number of adversaries overcome" (p. 1). These are referred to as the {\it sensory} and {\it measurement} streams, respectively \cite{Dosovitskiy:2016}.

%-------------------------------------------%



\section{Software}
%-------------------------------------------%

Predecessor or current software projects related to your capstone area. May be libraries that you are incorporating in your project, projects that are inspiring your design, a project you are building on, etc...

%-------------------------------------------%



\section{Other Sources}
%-------------------------------------------%

Non-academic sources such as white papers, manuals, blogs, etc.

%-------------------------------------------%